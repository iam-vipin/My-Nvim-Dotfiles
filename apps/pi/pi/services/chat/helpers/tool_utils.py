"""
Tool utilities shared across planning and execution.

This module intentionally centralizes non-core helpers used by the action executor
so that `action_executor.execute_action_with_retrieval` stays lean and readable.
"""

import asyncio
import logging
import re
from collections.abc import AsyncIterator
from typing import Any
from typing import Dict
from typing import List
from typing import Optional
from typing import Tuple
from typing import Union

from pi.services.chat.prompts import HISTORY_FRESHNESS_WARNING

log = logging.getLogger(__name__)

# build a map of tool name to category
TOOL_NAME_TO_CATEGORY_MAP: Dict[str, Dict[str, str]] = {
    # Assets
    "assets_create": {"entity_type": "asset", "action_type": "create", "front_facing_name": "Create Asset"},
    "assets_create_user_upload": {"entity_type": "asset", "action_type": "create", "front_facing_name": "Create Asset User Upload"},
    "assets_delete_user": {"entity_type": "asset", "action_type": "delete", "front_facing_name": "Delete Asset User"},
    "assets_get_generic": {"entity_type": "asset", "action_type": "get", "front_facing_name": "Get Asset Generic"},
    "assets_update_generic": {"entity_type": "asset", "action_type": "update", "front_facing_name": "Update Asset Generic"},
    "assets_update_user": {"entity_type": "asset", "action_type": "update", "front_facing_name": "Update Asset User"},
    # Attachments
    "attachments_create": {"entity_type": "attachment", "action_type": "create", "front_facing_name": "Create Attachment"},
    "attachments_delete": {"entity_type": "attachment", "action_type": "delete", "front_facing_name": "Delete Attachment"},
    # Comments
    "comments_create": {"entity_type": "comment", "action_type": "create", "front_facing_name": "Create Comment"},
    "comments_delete": {"entity_type": "comment", "action_type": "delete", "front_facing_name": "Delete Comment"},
    "comments_update": {"entity_type": "comment", "action_type": "update", "front_facing_name": "Update Comment"},
    # Cycles
    "cycles_add_work_items": {"entity_type": "cycle", "action_type": "add", "front_facing_name": "Add Work Items to Cycle"},
    "cycles_archive": {"entity_type": "cycle", "action_type": "archive", "front_facing_name": "Archive Cycle"},
    "cycles_create": {"entity_type": "cycle", "action_type": "create", "front_facing_name": "Create Cycle"},
    "cycles_remove_work_item": {"entity_type": "cycle", "action_type": "remove", "front_facing_name": "Remove Work Item from Cycle"},
    "cycles_transfer_work_items": {"entity_type": "cycle", "action_type": "transfer", "front_facing_name": "Transfer Work Items to Cycle"},
    "cycles_unarchive": {"entity_type": "cycle", "action_type": "unarchive", "front_facing_name": "Unarchive Cycle"},
    "cycles_update": {"entity_type": "cycle", "action_type": "update", "front_facing_name": "Update Cycle"},
    # Intakes
    "intake_create": {"entity_type": "intake", "action_type": "create", "front_facing_name": "Create Intake"},
    "intake_delete": {"entity_type": "intake", "action_type": "delete", "front_facing_name": "Delete Intake"},
    "intake_update": {"entity_type": "intake", "action_type": "update", "front_facing_name": "Update Intake"},
    # Labels
    "labels_create": {"entity_type": "label", "action_type": "create", "front_facing_name": "Create Label"},
    "labels_update": {"entity_type": "label", "action_type": "update", "front_facing_name": "Update Label"},
    # Links
    "links_create": {"entity_type": "link", "action_type": "create", "front_facing_name": "Create Link"},
    "links_delete": {"entity_type": "link", "action_type": "delete", "front_facing_name": "Delete Link"},
    "links_update": {"entity_type": "link", "action_type": "update", "front_facing_name": "Update Link"},
    # Modules
    "modules_add_work_items": {"entity_type": "module", "action_type": "add", "front_facing_name": "Add Work Items to Module"},
    "modules_archive": {"entity_type": "module", "action_type": "archive", "front_facing_name": "Archive Module"},
    "modules_create": {"entity_type": "module", "action_type": "create", "front_facing_name": "Create Module"},
    "modules_remove_work_item": {"entity_type": "module", "action_type": "remove", "front_facing_name": "Remove Work Item from Module"},
    "modules_unarchive": {"entity_type": "module", "action_type": "unarchive", "front_facing_name": "Unarchive Module"},
    "modules_update": {"entity_type": "module", "action_type": "update", "front_facing_name": "Update Module"},
    # Pages
    "pages_create_page": {"entity_type": "page", "action_type": "create", "front_facing_name": "Create Page"},
    "pages_create_project_page": {"entity_type": "page", "action_type": "create", "front_facing_name": "Create Project Page"},
    "pages_create_workspace_page": {"entity_type": "page", "action_type": "create", "front_facing_name": "Create Workspace Page"},
    # Projects
    "projects_archive": {"entity_type": "project", "action_type": "archive", "front_facing_name": "Archive Project"},
    "projects_create": {"entity_type": "project", "action_type": "create", "front_facing_name": "Create Project"},
    "projects_unarchive": {"entity_type": "project", "action_type": "unarchive", "front_facing_name": "Unarchive Project"},
    "projects_update": {"entity_type": "project", "action_type": "update", "front_facing_name": "Update Project"},
    "projects_retrieve": {"entity_type": "project", "action_type": "retrieve", "front_facing_name": "Retrieve Project"},
    # Properties
    "properties_create": {"entity_type": "property", "action_type": "create", "front_facing_name": "Create Property"},
    "properties_create_option": {"entity_type": "property", "action_type": "create_option", "front_facing_name": "Create Property Option"},
    "properties_create_value": {"entity_type": "property", "action_type": "create_value", "front_facing_name": "Create Property Value"},
    "properties_delete": {"entity_type": "property", "action_type": "delete", "front_facing_name": "Delete Property"},
    "properties_delete_option": {"entity_type": "property", "action_type": "delete_option", "front_facing_name": "Delete Property Option"},
    "properties_update": {"entity_type": "property", "action_type": "update", "front_facing_name": "Update Property"},
    "properties_update_option": {"entity_type": "property", "action_type": "update_option", "front_facing_name": "Update Property Option"},
    # States
    "states_create": {"entity_type": "state", "action_type": "create", "front_facing_name": "Create State"},
    "states_update": {"entity_type": "state", "action_type": "update", "front_facing_name": "Update State"},
    # Types
    "types_create": {"entity_type": "type", "action_type": "create", "front_facing_name": "Create Type"},
    "types_delete": {"entity_type": "type", "action_type": "delete", "front_facing_name": "Delete Type"},
    "types_update": {"entity_type": "type", "action_type": "update", "front_facing_name": "Update Type"},
    # Workitems and Epics
    "create_epic": {"entity_type": "epic", "action_type": "create", "front_facing_name": "Create Epic"},
    "update_epic": {"entity_type": "epic", "action_type": "update", "front_facing_name": "Update Epic"},
    "workitems_create": {"entity_type": "workitem", "action_type": "create", "front_facing_name": "Create Work Item"},
    "workitems_create_relation": {"entity_type": "workitem", "action_type": "update", "front_facing_name": "Create Work Item Relation"},
    "workitems_update": {"entity_type": "workitem", "action_type": "update", "front_facing_name": "Update Work Item"},
    "workitems_delete": {"entity_type": "workitem", "action_type": "delete", "front_facing_name": "Delete Work Item"},
    # Worklogs
    "worklogs_create": {"entity_type": "worklog", "action_type": "create", "front_facing_name": "Create Work Log"},
    "worklogs_delete": {"entity_type": "worklog", "action_type": "delete", "front_facing_name": "Delete Work Log"},
    "worklogs_update": {"entity_type": "worklog", "action_type": "update", "front_facing_name": "Update Work Log"},
}


def is_retrieval_tool(tool_name: Any) -> bool:
    """Return True if the tool is a retrieval/lookup tool.

    Heuristics:
    - search_* prefix
    - *_list or *_retrieve suffix
    - known retrieval utilities
    - empty/unknown names default to retrieval (defensive)
    """
    name = str(tool_name).strip() if tool_name is not None else ""
    if not name:
        return True
    # Prefix-based retrieval tools (entity search + list/get helpers)
    if name.startswith(("search_", "list_", "get_", "retrieve_")):
        return True
    # Suffix-based retrieval tools (legacy convention)
    if name.endswith("_list") or name.endswith("_retrieve"):
        return True
    # Known retrieval utilities
    if name in {"structured_db_tool", "vector_search_tool", "pages_search_tool", "docs_search_tool", "fetch_cycle_details"}:
        return True
    return False


"""Tool name mapping utilities and classification registry."""

# ------------------------------
# Tool classification registry
# ------------------------------

# kind: "retrieval" | "action"
# plan_only: True means never execute in planning; store as planned
TOOL_METADATA_REGISTRY: Dict[str, Dict[str, Any]] = {
    # Retrieval tools (execute immediately)
    "vector_search_tool": {"kind": "retrieval", "plan_only": False},
    "structured_db_tool": {"kind": "retrieval", "plan_only": False},
    "pages_search_tool": {"kind": "retrieval", "plan_only": False},
    "docs_search_tool": {"kind": "retrieval", "plan_only": False},
    "fetch_cycle_details": {"kind": "retrieval", "plan_only": False},
    # Planner/system helpers
    "ask_for_clarification": {"kind": "retrieval", "plan_only": False},
    # Common actions (examples - fallback to heuristics for unknown tools)
    "workitems_create": {"kind": "action", "plan_only": True},
    "workitems_update": {"kind": "action", "plan_only": True},
    "workitems_create_relation": {"kind": "action", "plan_only": True},
    "modules_add_work_items": {"kind": "action", "plan_only": True},
    "cycles_add_work_items": {"kind": "action", "plan_only": True},
    "create_epic": {"kind": "action", "plan_only": True},
    "projects_retrieve": {"kind": "retrieval", "plan_only": False},
}


def register_tool_metadata(name: str, *, kind: str, plan_only: bool = False) -> None:
    """Register or update tool metadata in the classification registry."""
    if not name:
        return
    TOOL_METADATA_REGISTRY[name] = {"kind": kind, "plan_only": bool(plan_only)}


def get_tool_metadata(name: str) -> Dict[str, Any]:
    """Return metadata for a tool if available; empty dict if unknown."""
    return TOOL_METADATA_REGISTRY.get(name, {})


def is_plan_only_tool(name: str) -> bool:
    """Return True if the tool must not be executed during planning (planned only)."""
    return bool(TOOL_METADATA_REGISTRY.get(name, {}).get("plan_only", False))


import contextlib

from pi.services.schemas.chat import RetrievalTools


def tool_name_to_retrieval_tool(tool_name: str) -> str:
    """Convert tool name back to retrieval tool enum value."""
    tool_to_enum_map = {
        "vector_search_tool": RetrievalTools.VECTOR_SEARCH_TOOL,
        "structured_db_tool": RetrievalTools.STRUCTURED_DB_TOOL,
        "pages_search_tool": RetrievalTools.PAGES_SEARCH_TOOL,
        "docs_search_tool": RetrievalTools.DOCS_SEARCH_TOOL,
        "action_executor_agent": RetrievalTools.ACTION_EXECUTOR_TOOL,
    }
    return tool_to_enum_map.get(tool_name, tool_name)


def tool_name_shown_to_user(tool_name: str) -> str:
    """Convert tool name to a user-friendly name."""
    tool_to_user_map = {
        "vector_search_tool": "Semantic search",
        "structured_db_tool": "Database querying",
        "search_current_cycle": "Find Current Cycle",
        "fetch_cycle_details": "Cycle Details",
        "list_recent_cycles": "Recent Cycles",
        "pages_search_tool": "Semantic search of pages",
        "docs_search_tool": "Semantic search of docs",
        "action_executor_agent": "Action Execution",
        # Entity search tools
        "search_project_by_name": "Search Project",
        "search_project_by_identifier": "Search Project by Identifier",
        "search_module_by_name": "Search Module",
        "search_cycle_by_name": "Search Cycle",
        "search_state_by_name": "Search State",
        "search_label_by_name": "Search Label",
        "search_user_by_name": "Search User",
        "search_workitem_by_name": "Search Work-item",
        "search_workitem_by_identifier": "Search Work-item by ID",
        # Other common tools
        "states_list": "List States",
        "projects_list": "List Projects",
        "modules_list": "List Modules",
        "cycles_list": "List Cycles",
        "labels_list": "List Labels",
        "users_list": "List Users",
        "workitems_list": "List Work-items",
        "list_member_projects": "List Member Projects",
    }
    name_to_return = tool_to_user_map.get(tool_name, "")
    if not name_to_return:
        name_to_return = TOOL_NAME_TO_CATEGORY_MAP.get(tool_name, {}).get("front_facing_name", tool_name)
    return name_to_return


def category_display_name(category: str) -> str:
    """
    Convert internal category slug to a user-friendly display name.
    Falls back to Title Case of the slug with underscores replaced.
    """

    category = category.strip().lower()
    overrides = {
        "workitems": "Work items",
        "worklogs": "Work logs",
        "projects": "Projects",
        "cycles": "Cycles",
        "modules": "Modules",
        "labels": "Labels",
        "states": "States",
        "pages": "Pages",
        "assets": "Assets",
        "users": "Users",
        "members": "Members",
        "activity": "Activity",
        "attachments": "Attachments",
        "comments": "Comments",
        "links": "Links",
        "properties": "Properties",
        "types": "Types",
        "intake": "Intake",
    }
    return overrides.get(category, category.replace("_", " ").title())


def is_uuid_like(value: Any) -> bool:
    """Check if a value looks like a UUID."""
    if not isinstance(value, str):
        return False
    # UUID pattern: 8-4-4-4-12 hex digits with optional hyphens
    uuid_pattern = re.compile(r"^[0-9a-f]{8}-?[0-9a-f]{4}-?[0-9a-f]{4}-?[0-9a-f]{4}-?[0-9a-f]{12}$", re.IGNORECASE)
    return bool(uuid_pattern.match(value.strip()))


def is_url(value: Any) -> bool:
    """Check if a value looks like a URL."""
    if not isinstance(value, str):
        return False
    return value.startswith(("http://", "https://", "ftp://"))


def clean_result_dict(data: Any, depth: int = 0) -> Any:
    """
    Recursively clean a result dictionary by removing UUIDs, URLs, and technical fields.
    Keeps user-friendly fields like names, identifiers, counts, dates, etc.

    Args:
        data: The data structure to clean (dict, list, or primitive)
        depth: Current recursion depth (to prevent infinite loops)

    Returns:
        Cleaned data structure
    """
    if depth > 10:  # Safety limit
        return "..."

    # Fields to always exclude
    EXCLUDE_FIELDS = {
        "id",
        "project_id",
        "workspace_id",
        "user_id",
        "member_id",
        "cycle_id",
        "module_id",
        "state_id",
        "label_id",
        "type_id",
        "parent_id",
        "url",
        "entity_url",
        "workspace",
        "created_by_id",
        "updated_by_id",
        "owner_id",
        "assignee_id",
        "reporter_id",
        "lead_id",
    }

    # Fields to always keep (even if they look like UUIDs)
    KEEP_FIELDS = {
        "name",
        "identifier",
        "title",
        "description",
        "count",
        "total",
        "status",
        "priority",
        "state",
        "type",
        "access",
        "color",
        "start_date",
        "end_date",
        "target_date",
        "created_at",
        "updated_at",
        "is_current",
        "is_active",
        "is_draft",
        "is_archived",
    }

    if isinstance(data, dict):
        cleaned = {}
        for key, value in data.items():
            key_lower = key.lower()

            # Skip excluded fields
            if key_lower in EXCLUDE_FIELDS:
                continue

            # Skip UUID-like values unless it's a keep field
            if is_uuid_like(value) and key_lower not in KEEP_FIELDS:
                continue

            # Skip URLs
            if is_url(value):
                continue

            # Recursively clean nested structures
            cleaned_value = clean_result_dict(value, depth + 1)

            # Only include non-empty cleaned values
            if cleaned_value not in (None, {}, []):
                cleaned[key] = cleaned_value

        return cleaned or None

    elif isinstance(data, list):
        cleaned_list = []
        for item in data:
            cleaned_item = clean_result_dict(item, depth + 1)
            if cleaned_item not in (None, {}, []):
                cleaned_list.append(cleaned_item)
        return cleaned_list or None

    else:
        # Primitives: return as-is unless it's a UUID or URL
        if is_uuid_like(data) or is_url(data):
            return None
        return data


def format_tool_message_for_display(content: Optional[str | dict]) -> str:
    """
    Parse and clean tool message content for user-friendly display.
    Removes UUIDs, URLs, and technical fields while preserving meaningful information.

    Args:
        content: Raw tool message content string (or dict that will be converted)

    Returns:
        Cleaned, user-friendly tool message string
    """
    if not content:
        return ""

    # Handle case where content is still a dict (shouldn't happen but defensive)
    if isinstance(content, dict):
        # Extract just the message field if it's a structured response
        if "message" in content:
            return content["message"]
        # Otherwise convert to string
        content = str(content)

    try:
        # Split into message and result parts
        parts = content.split("\n\nResult:", 1)
        success_message = parts[0].strip() if parts else ""
        result_part = parts[1].strip() if len(parts) > 1 else ""

        if not result_part:
            # No result section, just return the message as-is
            return content

        # We have a Result section - hide it and return just the message
        # The LLM gets the full data, user only sees the clean message
        return success_message or "✅ Operation completed successfully"

    except Exception as e:
        # On any error, return original for debugging purposes but log it
        log.debug(f"Error formatting tool message: {e}")
        return content


def retrieval_tool_to_tool_name(retrieval_tool: str) -> str:
    """Convert retrieval tool enum value to corresponding LangChain tool name."""
    enum_to_tool_map = {
        "vector_search_tool": "vector_search_tool",
        "structured_db_tool": "structured_db_tool",
        "pages_search_tool": "pages_search_tool",
        "docs_search_tool": "docs_search_tool",
        "action_executor_tool": "action_executor_agent",
    }
    return enum_to_tool_map.get(retrieval_tool, retrieval_tool)


# Legacy function name for backward compatibility
agent_to_tool_name = retrieval_tool_to_tool_name


def log_toolset_details(tools: List[Any], chat_id: str) -> None:
    """Log detailed information about a toolset including argument schemas.

    Args:
        tools: List of LangChain tools to log
        chat_id: Chat ID for logging context
    """
    log.info(f"ChatID: {chat_id} - Re-binding LLM with the full toolset ({len(tools)} tools):")

    for i, tool in enumerate(tools, 1):
        tool_name = getattr(tool, "name", "Unknown")
        tool_desc = getattr(tool, "description", "No description")
        log.info(f"  {i:2d}. {tool_name}: {tool_desc}")

        # Try to introspect and print the argument schema for each tool
        args_schema = getattr(tool, "args_schema", None)
        if args_schema is not None:
            try:
                # Pydantic v2 style: model_fields
                if hasattr(args_schema, "model_fields"):
                    fields = getattr(args_schema, "model_fields", {}) or {}
                    if fields:
                        for field_name, field in fields.items():
                            try:
                                annotation = getattr(field, "annotation", None)
                                field_type = getattr(annotation, "__name__", None) or str(annotation)
                            except Exception:
                                field_type = "Any"
                            # Determine required and default
                            is_required = False
                            try:
                                if hasattr(field, "is_required") and callable(field.is_required):
                                    is_required = bool(field.is_required())
                                else:
                                    is_required = getattr(field, "default", None) is None and not bool(getattr(field, "default_factory", None))
                            except Exception:
                                pass
                            default_value = getattr(field, "default", None)
                            log.info(f"       - {field_name}: type={field_type}, required={is_required}, default={default_value!r}")
                # Pydantic v1 style: schema()
                elif hasattr(args_schema, "schema") and callable(getattr(args_schema, "schema")):
                    schema_dict = args_schema.schema()
                    properties = schema_dict.get("properties", {}) or {}
                    required_list = schema_dict.get("required", []) or []
                    for field_name, meta in properties.items():
                        field_type = meta.get("type") or meta.get("title") or str(meta.get("anyOf") or "Any")
                        default_value = meta.get("default", None)
                        is_required = field_name in required_list
                        log.info(f"       - {field_name}: type={field_type}, required={is_required}, default={default_value!r}")
            except Exception as schema_err:
                log.info(f"       - (args_schema introspection failed: {schema_err})")
        else:
            # Fallback: inspect function signature if available
            func = getattr(tool, "coroutine", None) or getattr(tool, "func", None)
            if func is not None:
                try:
                    import inspect as _inspect

                    sig = _inspect.signature(func)
                    for param in sig.parameters.values():
                        if param.name == "self":
                            continue
                        annotation = None if param.annotation is _inspect._empty else param.annotation
                        ann_str = getattr(annotation, "__name__", None) or str(annotation)
                        default_value = None if param.default is _inspect._empty else param.default
                        log.info(f"       - {param.name}: type={ann_str}, default={default_value!r}")
                except Exception as sig_err:
                    log.info(f"       - (signature introspection failed: {sig_err})")


# ------------------------------
# Action Executor helper methods
# ------------------------------

# TOOL_CALL_REASONING_INSTRUCTIONS = """**MANDATORY REASONING AND COMMUNICATION (CRITICAL - REQUIRED FOR EVERY TOOL CALL):**
# - **BEFORE EACH TOOL CALL**: You MUST explain your reasoning and intent
#   - State what information you're trying to gather or what action you're planning
#   - Explain why this tool is necessary for completing the user's request
#   - Describe what you expect to get from the tool and how you'll use it
#   - Example: "The user wants to check workitems assigned to Anil. First, I need to search for the user 'Anil' to get their ID, then I'll use that ID to filter workitems." # noqa: E501
# - **AFTER EACH TOOL CALL**: You MUST provide a brief summary of what you learned
#   - Summarize key information obtained from the tool
#   - Explain how this information helps with the next step
#   - If the tool returned unexpected results, explain how you'll adapt
#   - Example: "Found user Anil Kumar with ID xyz-123. Now I'll use this ID to search for workitems assigned to them." # noqa: E501
# - **THINKING OUT LOUD**: Express your thought process naturally
#   - Share your understanding of the user's request
#   - Explain your strategy for accomplishing the task
#   - Mention any assumptions you're making
# - This reasoning is MANDATORY and helps with debugging and understanding your decision-making process
# - NEVER skip the reasoning - it's essential for transparency and troubleshooting"""  # noqa: E501


# TOOL_CALL_REASONING_REINFORCEMENT = """**FINAL MANDATORY REQUIREMENT - REASONING FOR EVERY TOOL CALL:**
# You MUST provide clear reasoning in your response content BEFORE and AFTER each tool call:
# - BEFORE: Explain what you're about to do and why (e.g., "Let me first find user Anil's details to get their ID...") # noqa: E501
# - AFTER: Summarize what you found and your next step (e.g., "Found Anil Kumar (ID: xyz-123). Now searching for workitems assigned to them...") # noqa: E501
# - This reasoning is NOT optional - it's required for transparency and helps users understand your process
# - Even for simple searches, explain your thinking (e.g., "Searching for project 'Mobile' to get its UUID for creating workitems...")
# - Provide this in the content field surrounding your tool_calls"""  # noqa: E501

app_response_instructions = """

**CRITICAL - APP INTEGRATION RESPONSE:**
You have access to a special tool: `provide_final_answer_for_app`

**WHEN TO USE THIS TOOL:**
- After you have gathered all necessary information via retrieval tools
- When you have completed answering the user's question
- ONLY for retrieval/informational queries (NOT for modification requests with actions)

**HOW TO USE:**
Call `provide_final_answer_for_app` with:
1. **text_response**: Your comprehensive natural language answer (be detailed and well-formatted)
2. **entities**: List of relevant entities from the retrieval results

**Entity format for each item:**
- **type**: Entity type (workitem, project, cycle, module, page, user, label, state, etc.)
- **name**: Entity name/title
- **properties**: Dictionary containing relevant fields:
  - id: Entity UUID (when available)
  - identifier: Human-readable ID like PROJECT-123 (for workitems)
  - state: Current state (for workitems)
  - priority: Priority level (for workitems)
  - assignee: Assigned user name (for workitems)
  - status: Status (for cycles/modules)
  - ... other relevant fields based on entity type

NOTE: Do NOT include 'url' in properties - URLs are added automatically by the system.

**Example:**
```
provide_final_answer_for_app(
    text_response="You have 3 high priority work items assigned to you:\n1. Fix login bug (PROJ-123) - In Progress\n2. Update documentation (PROJ-124) - Todo\n3. Refactor API (PROJ-125) - In Progress",
    entities=[
        {
            "type": "workitem",
            "name": "Fix login bug",
            "properties": {
                "id": "abc-123-uuid",
                "identifier": "PROJ-123",
                "state": "In Progress",
                "priority": "high",
                "assignee": "John Doe"
            }
        },
        {
            "type": "workitem",
            "name": "Update documentation",
            "properties": {
                "id": "def-456-uuid",
                "identifier": "PROJ-124",
                "state": "Todo",
                "priority": "high",
                "assignee": "John Doe"
            }
        },
        {
            "type": "workitem",
            "name": "Refactor API",
            "properties": {
                "id": "ghi-789-uuid",
                "identifier": "PROJ-125",
                "state": "In Progress",
                "priority": "high",
                "assignee": "John Doe"
            }
        }
    ]
)
```

**This will be formatted as:**
```json
{
  "text": "You have 3 high priority work items... (PROJ-123) - In Progress...",
  "entities": [{"type": "workitem", "name": "Fix login bug", "properties": {"url": "https://...", "identifier": "PROJ-123", ...}}]
}
```
**CRITICAL - REGARDING ENTITIES:**
- Extract entity information from retrieval tool results
- Only include entities if they are the **actual subject** of the user's query. Do not include supporting/contextual entities.
- Do NOT include entities that are merely context or filters for the query.
- Only include entities that are the direct answer to what the user asked for.
- If no specific entities are the direct answer, pass an empty list for entities
- This structured format enables rich display in external applications like Slack
"""  # noqa E501

work_tree_instructions_normal_response = """
**IF the user's request is informational/retrieval-only (questions, searches, listing, checking status):**
1. Use retrieval/search tools to gather the requested information
2. Provide a detailed, elaborate, and neatly formatted answer in the content section based on the retrieved data. Do NOT be brief.
3. Do NOT plan any modifying actions - just return tool_calls for retrieval, then answer in your content
4. **Formatting Requirements**:
    While formatting the answer in the final content section, use the following rules:
    - Use "work-item" (not "issue") and "unique key" (not "Issue ID") terminology
    - Suppress UUIDs - they are PII (exception: unique keys like PAI-123 are not UUIDs, can show)
    - No hallucination - if no data, say so clearly without mentioning SQL/tools/internals
    - Never reveal sensitive info: passwords, API keys, table names, SQL queries
    - Create clickable URLs: `[PAI-123](url)` for work-items, `[name](url)` for others
    - Use tables for multi-attribute data (suppress UUIDs, apply URL rules)
5. The requirement for an elaborate answer doesn't apply to modification requests - those require action planning followed by a very brief summary.

**IF the user's request requires modifying data (create, update, delete, move, assign, etc.):**
1. Use retrieval/search tools to gather necessary information (IDs, etc.)
2. **AND** plan at least one MODIFYING ACTION using tool_calls (create, update, delete, add, remove, move, etc.)
3. You CANNOT stop after just searching/retrieving - you MUST plan the modifying actions with tool_calls
4. Provide a very brief summary of what you planned in your content
5. **Formatting Requirements**:
    While formatting the action plan in the final content section, use the following rules:
    - Use "work-item" (not "issue") and "unique key" (not "Issue ID") terminology
    - Suppress UUIDs - they are PII (exception: unique keys like PAI-123 are not UUIDs, can show)
    - Never reveal sensitive info: passwords, API keys, table names, SQL queries
    - Create clickable URLs: `[PAI-123](url)` for work-items, `[name](url)` for others


**IF the user's request cannot be fulfilled with available tools:**
- Examples: Analytics/visualizations, external integrations, bulk operations, administrative functions, file uploads
- Use retrieval tools if relevant to understand the request
- Then provide a polite, brief explanation of why it cannot be done and what alternatives exist (if any)
- Do NOT create workaround entities (like workitems) to satisfy these requests
- Do NOT plan any actions - just provide the explanation in your content

Note: The system uses absence of tool_calls as the signal to stop and deliver your content as the final answer. For modification requests, include at least one write tool_call in your plan.
"""  # noqa E501

work_tree_instructions_app_response = f"""
**IF the user's request is informational/retrieval-only (questions, searches, listing, checking status):**
1. Use retrieval/search tools to gather the requested information
2. Provide a detailed, elaborate, and neatly formatted answer in the 'text' field in the provide_final_answer_for_app tool based on the retrieved data. Do NOT be brief.
3. Do NOT plan any modifying actions - just return tool_calls for retrieval, then call provide_final_answer_for_app
4. **Formatting Requirements**:
    While formatting the answer in the 'text' field in the provide_final_answer_for_app tool, use the following rules:
    - Use "work-item" (not "issue") and "unique key" (not "Issue ID") terminology
    - Suppress UUIDs - they are PII (exception: unique keys like PAI-123 are not UUIDs, can show)
    - **CRITICAL: DO NOT create markdown links like [text](url) in the text field**
    - **URLs are added programmatically to entity properties - you must NOT include them**
    - You can reference entities by identifier (e.g., "PROJ-123") but NOT as markdown links
    - Use plain text references only: "Fix login bug (PROJ-123)" not "[PROJ-123](url)"
    - No hallucination - if no data, say so clearly without mentioning SQL/tools/internals
    - Never reveal sensitive info: passwords, API keys, table names, SQL queries
    - Never ever use tables, because the external app will not be able to parse any content other than text.
5. The requirement for an elaborate answer doesn't apply to modification requests - those require action planning followed by a very brief summary.

{app_response_instructions}

**IF the user's request requires modifying data (create, update, delete, move, assign, etc.):**
1. Use retrieval/search tools to gather necessary information (IDs, etc.)
2. **AND** plan at least one MODIFYING ACTION using tool_calls (create, update, delete, add, remove, move, etc.)
3. You CANNOT stop after just searching/retrieving - you MUST plan the modifying actions with tool_calls
4. Provide a very brief summary of what you planned in your content
5. **Formatting Requirements**:
    While formatting the action plan in the final content section, use the following rules:
    - Use "work-item" (not "issue") and "unique key" (not "Issue ID") terminology
    - Suppress UUIDs - they are PII (exception: unique keys like PAI-123 are not UUIDs, can show)
    - Never reveal sensitive info: passwords, API keys, table names, SQL queries
    - Create clickable URLs: `[PAI-123](url)` for work-items, `[name](url)` for others

**IF the user's request cannot be fulfilled with available tools:**
- Examples: Analytics/visualizations, external integrations, bulk operations, administrative functions, file uploads
- Use retrieval tools if relevant to understand the request
- Then provide a polite, brief explanation of why it cannot be done and what alternatives exist (if any)
- Do NOT create workaround entities (like workitems) to satisfy these requests
- Do NOT plan any actions - just provide the explanation in your content

Note: This is a response for consumption by an external app. So, calling provide_final_answer_for_app signals completion for retrieval-only requests. For modification requests, include at least one write tool_call in your plan.
"""  # noqa E501


# Build the planning method prompt used by the executor
def build_method_prompt(
    combined_tool_query: str,
    project_id: Optional[str],
    user_id: Optional[str],
    workspace_id: Optional[str],
    enhanced_conversation_history: Optional[str],
    clarification_context: Optional[Dict[str, Any]] = None,
    user_meta: Optional[Dict[str, Any]] = None,
    source: Optional[str] = None,
) -> str:
    from pi.services.chat.prompts import RETRIEVAL_TOOL_DESCRIPTIONS
    from pi.services.chat.prompts import plane_context

    address_user_by_name = True

    WORK_TREE_INSTRUCTIONS = work_tree_instructions_app_response if source == "app" else work_tree_instructions_normal_response

    method_prompt = f"""You are an AI assistant that helps users perform actions in Plane.

Context about Plane:
{plane_context}

**IMPORTANT: You are in PLANNING mode with a TWO-PHASE APPROACH:**

**PHASE 1 - INFORMATION GATHERING (executes immediately):**
- Retrieval tools (search_*, *_list, *_retrieve, structured_db_tool, etc.) execute immediately
- These tools gather information you need (IDs, names, etc.)
- No user approval required for these tools

**PHASE 2 - ACTION PLANNING (requires user approval):**
- Modifying actions (*_create, *_update, *_add, *_remove, etc.) are PLANNED only
- These actions will be presented to the user for approval
- After user clicks "Confirm", actions execute in a separate phase

Use retrieval tools to gather information, then plan the modifying actions based on that information.

**DATA FRESHNESS RULE (CRITICAL — WORKSPACE DATA IS VOLATILE):**
- Workspace, project, cycle, module, label, state, and work-item data is LIVE and can change at any moment.
- Users or automations may create, update, or delete entities at any time during the conversation.
- Therefore, you MUST NOT assume that prior retrieval results are still valid.
- Whenever the user asks to "check again", "retry", "verify now", "refresh", or otherwise implies that data may have changed, you MUST perform fresh retrieval tool calls.
- Only static, non-user-modifiable information (documentation, product descriptions, or system defaults) may be reused from memory.
- For ALL modifying requests in PLANNING mode, retrieval should ALWAYS reflect the most recent state—never rely solely on earlier tool outputs.

**CRITICAL: PLANNING DEPENDENT ACTIONS**
- You must plan ALL actions including dependent ones that link created entities
- For dependent actions, use logical parameter references that show the relationship
- The system will resolve these references during actual execution

**Planning Guidelines:**
- Use retrieval tools to gather necessary information (projects, modules, etc.)
- Plan ALL required actions for the complete task
- For interlinked actions, plan both actions
- Once you have planned all necessary actions, STOP and do not plan any more
- Do not repeat the same action multiple times
- Do not try to execute actions - only plan them
- For multi-property updates, resolve all required IDs first, then set all properties in a single tool call

**WORKSPACE-LEVEL QUERIES (EFFICIENCY):**
|- When query is related to workitems and spans ALL projects without specifying a particular project or projects
|  - DO NOT: call `list_member_projects` then query each project with `structured_db_tool` separately
|  - INSTEAD: Use ONE `structured_db_tool` call WITHOUT `project_id` parameter
|  - Query will automatically scope to workspace via `workspace_id` (already in context)
|  - Example WRONG: `list_member_projects` + 7x `structured_db_tool` (each with different project_id)
|  - Example RIGHT: Single `structured_db_tool`: "list all workitems prioritized as high"
|- For project-specific queries, include the specific `project_id`

**PROJECT FEATURES CHECK (CRITICAL - MANDATORY BEFORE CREATING PROJECT-SCOPED ENTITIES):**
- Cycles, modules, pages, workitem types, views, intake, and time-tracking (worklogs) are project-level features that are enabled/disabled on a per-project basis.
- **MANDATORY WORKFLOW**: Before creating ANY of these entities (cycles_create, modules_create, pages_create_*, worklogs_create, etc.), you MUST:
    1. First get the project_id (via search_project_by_name or search_project_by_identifier if not already known)
    2. **THEN** call `projects_retrieve` with that project_id to check if the feature is enabled
    3. **AFTER checking**: You MUST plan the required actions using tool_calls:
       - If the feature IS enabled: Plan the creation action (e.g., `cycles_create`, `modules_create`, `worklogs_create`)
       - If the feature is NOT enabled: Plan BOTH `projects_update` (to enable the feature) AND the creation action (e.g., `cycles_create`, `modules_create`, `worklogs_create`)
    4. **CRITICAL**: After `projects_retrieve` completes, you CANNOT stop - you MUST continue planning the modifying actions. Do NOT return only text - you MUST return tool_calls for the planned actions.
    5. **REMEMBER**: `projects_retrieve` is ONLY for information gathering. The user's actual request (create cycle/module/page/worklog) is NOT complete until you plan the creation action with tool_calls. Do NOT stop after retrieval - the task is incomplete without planning the creation.
- **CRITICAL**: This check is NON-NEGOTIABLE. Never skip the `projects_retrieve` step when creating cycles, modules, pages, or other project-scoped features.
- **CRITICAL**: After retrieving project features, you MUST plan the actions - do NOT stop after retrieval. The user requested a modification (create cycle/module/page/worklog), so you MUST plan it with tool_calls.
- **EXCEPTION (NEW PROJECT IN CURRENT PLAN)**: If the target project is being CREATED in this same plan and does not yet have a real UUID, do NOT call `projects_retrieve` during planning. Use placeholders for downstream actions and defer any feature checks until after execution or when working with an existing project that has a UUID.
- Available tools:
    - `projects_retrieve` tool to get details of the project features (MUST call before creating project-scoped entities)
    - `projects_update` tool to update the project features (MUST include in plan if feature needs to be enabled)
    - `projects_create` tool to create a new project with any/all of these features based on the user's request

**HARD CONSTRAINTS FOR TOOL CALLS (NON-NEGOTIABLE):**
- If the request involves modification of data like creating, updating, adding, removing, moving, assigning, archiving, or unarchiving: you MUST return one or more tool_calls for the corresponding action tools (e.g., cycles_create, workitems_create, modules_add_work_items). Returning only text is incorrect.
    - For modification requests, keep text content brief - do NOT provide meta commentary like "I will plan..." or ask user to click 'Confirm'
    - System handles approval automatically
    - If required information is missing, call ask_for_clarification instead of skipping tool_calls.


**RETRIEVAL RESULT RELEVANCE IN PLANNING ACTIONS FOR MODIFYING REQUESTS (CRITICAL):**
- Treat retrieval results as candidates, not ground truth.
- Use results ONLY if they directly match the user's current intent and entities; otherwise ignore them.
- Never copy retrieval text verbatim into parameters like description_html unless the user explicitly asked for it.
- When the user provides guidance about what should be in a description (e.g., "with details about X"), generate intelligent, informative content based on that topic - do NOT just copy the user's instruction text verbatim into the description.
- If the user's request doesn't refer to any specific topic to fill in the description, or is vague or unclear, provide a concise description synthesized from the user's request when uncertain.
- Always scope retrieval to the current project_id when available; do not use workspace-wide results if a project is set.

**PLURAL GENERATION POLICY (CRITICAL):**
- When the user intent is to create/add multiple entities (plural) and the user does not provide a list:
  - Generate a reasonable set (default 5-10) of distinct, actionable titles with short descriptions (when applicable) based on the user's theme/context.
  - Plan a separate create/add call for each item in that set (do not collapse to one).
  - Avoid using the project name itself as a entity title; titles should be specific to the entity type.
  - Keep titles concise; descriptions one or two sentences; ensure they are clearly relevant to the theme.
  - If the user hints at volume (e.g., "a few", "several", "a dozen"), align the count accordingly.

**ENTITY SEARCH FALLBACK AND DISAMBIGUATION RULES:**
- **Lookup fallback**: If one of the search tools for a given entity type fails or returns "Invalid identifier format", immediately try the next search tool for that entity type with the same query
- **Multiple matches**: If the search tool for a given entity type returns multiple candidates (users, work-items, etc.), call `ask_for_clarification` with:
  - `reason`: "Multiple matches found for [entity_type]"
  - `questions`: ["Which [entity] did you mean?"]
  - `disambiguation_options`: List the candidates with key details (name, id, email for users; name, id, project for work-items; and so on)
- **Zero matches**: If all search tools for a given entity type return no results, call `ask_for_clarification` with:
  - `reason`: "No [entity_type] found matching '[query]'"
  - `questions`: ["Could you provide more details or check the spelling?"]
- **CRITICAL**: Always attempt fallback searches before giving up or asking for clarification
- **MISSING PROJECT FOR PROJECT-SCOPED ENTITIES**: If you need a project list for scope selection or disambiguation:
  - **PREFER** `list_member_projects` to get active (unarchived, undeleted) projects the user is a member of
  - THEN call `ask_for_clarification` with `disambiguation_options` containing these filtered projects
  - **AVOID** using `structured_db_tool` or `projects_list` for project selection - they may include archived projects
- **No identical retries**: Do not call the same retrieval tool with the exact same parameters more than once. If it returns no/invalid results, proceed to the next fallback (within the same entity type) or ask for clarification.
  - **Do not loop the same call.**

**CRITICAL: ENTITY ID RESOLUTION AND PLACEHOLDER RULES**

**RULE 1: EXISTING ENTITIES - USE ACTUAL UUIDs (NO PLACEHOLDERS)**
When the user mentions an EXISTING entity (one that already exists in Plane):
- **YOU MUST**: Call the appropriate search tool FIRST to get its UUID
  - project NAME → `search_project_by_name` → extract UUID from response
  - project IDENTIFIER (e.g., 'HYDR', 'PARM') → `search_project_by_identifier` → extract UUID
  - cycle/module/label/state/user/workitem NAME/IDENTIFIER → `search_*_by_name` / `search_*_by_identifier` → extract UUID
  - **EXCEPTION**: User pronouns ('me', 'my', 'I', 'mine') → use User ID from USER CONTEXT directly
- **YOU MUST**: Extract the actual UUID from the search tool response (usually in the `id` field)
- **YOU MUST**: Use that extracted UUID directly in ALL subsequent tool calls
- **FORBIDDEN**: Using placeholders like `<id of workitem: ask>` for existing entities
- **FORBIDDEN**: Using names/identifiers directly as *_id parameters (e.g., `project_id: "Mobile"`)

**CRITICAL - PROPERTY VALUES RESOLUTION:**
When setting properties (state, labels, assignees, types) on work items, you MUST resolve names to IDs:
- **state property**: "change state to done" → call `search_state_by_name("done", project_id=...)` → extract `state_id` → use in action
- **labels property**: "add label 'bug'" → call `search_label_by_name("bug", project_id=...)` → extract `label_id` → use in action
- **assignees property**: "assign to John" → call `search_user_by_name("John")` → extract `user_id` → use in action
- **type property**: "change type to task" → call `search_type_by_name("task", project_id=...)` → extract `type_id` → use in action
- **NEVER** use property names directly (e.g., `state: {{name: "backlog"}}` ❌) - always resolve to ID first (e.g., `state_id: "uuid-123-eabc3cf2e"` ✅)


**RULE 2: NEWLY CREATED ENTITIES - USE PLACEHOLDERS**
When planning actions that depend on entities you CREATE in the CURRENT PLAN:
- **YOU MAY**: Use placeholder references for newly created entities
- **PLACEHOLDER FORMAT**: `<id of entity_type: entity_name>`
  - Module created in this plan: `<id of module: my-module>`
  - Workitem created in this plan: `<id of workitem: bug fix>`
  - Cycle created in this plan: `<id of cycle: Sprint 24>`
  - Project created in this plan: `<id of project: my-project>`
- **EXECUTION**: The system will resolve these placeholders during execution after the entities are created

**CRITICAL EXAMPLES - MIXED EXISTING AND NEW ENTITIES:**

Example 1: "Add workitems 'Login Page' and 'Logout Page' to new cycle 'Sprint 24'"
- Step 1: search_workitem_by_name("Login Page") → Response:
    {{
        "id": "abc-123-uuid",
        "name": "Login Page"
    }}
    → Extract UUID: abc-123-uuid
- Step 2: search_workitem_by_name("Logout Page") → Response:
    {{
        "id": "def-456-uuid",
        "name": "Logout Page"
    }}
    → Extract UUID: def-456-uuid
- Step 3: Plan cycles_create(name="Sprint 24") → New cycle, will use placeholder
- Step 4: Plan cycles_add_work_items:
  - cycle_id: '<id of cycle: Sprint 24>' ✅ CORRECT (newly created - use placeholder)
  - issues: ['abc-123-uuid', 'def-456-uuid'] ✅ CORRECT (existing - use actual UUIDs from search)
  - ❌ WRONG: issues: ['<id of workitem: Login Page>', '<id of workitem: Logout Page>'] (these are existing!)

Example 2: "Create workitem 'Fix login bug' and add it to existing module 'Backend'"
- Step 1: search_module_by_name("Backend") → Extract UUID: "module-xyz-uuid"
- Step 2: Plan workitems_create(name="Fix login bug") → New workitem, will use placeholder
- Step 3: Plan modules_add_work_items:
  - module_id: 'module-xyz-uuid' ✅ CORRECT (existing - use actual UUID from search)
  - issues: ['<id of workitem: Fix login bug>'] ✅ CORRECT (newly created - use placeholder)
  - ❌ WRONG: module_id: '<id of module: Backend>' (this module already exists!)

**PROJECT-SCOPED ENTITIES - ADDITIONAL REQUIREMENT:**
After resolving project_id for cycles/modules/pages creation:
- **YOU MUST**: Call `projects_retrieve(project_id=...)` to verify the feature is enabled
- **EXCEPTION**: If the project itself is being CREATED in this plan, skip `projects_retrieve` (no UUID yet)

**ID VALIDATION FOR RETRIEVAL TOOLS (STRICT):**
- NEVER pass placeholders like `<id of X: name>` to `*_retrieve`, `*_list`, or `*_get` tools
- ONLY pass real UUIDs to retrieval tools
- Do NOT retrieve entities that are only PLANNED (wait until after execution when UUID exists)
- If you have a name: search first → extract UUID → then retrieve
- If you have a placeholder: do NOT call retrieval until it's resolved to a UUID


**WORKSPACE-LEVEL CONTEXT - USE PROJECT FROM HISTORY:**
- In workspace-level chats (no explicit project pre-selected), if the conversation history clearly shows a specific project selection or creation (e.g., an executed action with "Entity: <project name> (<uuid>)" or a project URL containing the UUID), you MUST include that exact UUID as `project_id` for all project-scoped tools (e.g., `workitems_create`, `workitems_update`, `modules_*`, `cycles_*`).
- Prefer the most recent project in the history when multiple appear; if multiple conflicting projects are present, disambiguate by selecting the one explicitly referenced in the current user request; otherwise ask for clarification.
- Only omit `project_id` when no project is inferable from the history or current query.

**IMPORTANT**: Only plan modifying actions if the user's request actually requires modifying data. If the request cannot be fulfilled with available tools (e.g., analytics, visualizations, external integrations), provide a polite explanation instead of creating workaround entities.

**INTERLINKED ACTIONS GUIDANCE:**
- **Multi-step operations**: When a request involves multiple related actions, you MUST plan ALL of them
- **Creation + Assignment**: If creating an entity and then assigning it somewhere, plan both actions
- **Creation + Configuration**: If creating an entity and then configuring it, plan both actions
- **Moving/Adding to containers**: To move a work item to a module/cycle, use the appropriate add action
- **Dependency chains**: Plan actions in logical order (e.g., create first, then assign/configure)

**CRITICAL DISTINCTION - MOVE vs CREATE:**
- **"MOVE existing X to Y"** = Find X's ID, then use Y_add_* action (do NOT create new X)
- **"CREATE new X in Y"** = Use X_create action, then Y_add_* action

**WORK-ITEM CREATION CAPABILITIES:**
**✅ CAN be set during workitems_create:**
- name, description, priority, state, assignees, labels, story_points, start_date, target_date
- **EPIC CREATION**: Use `create_epic` tool to create epics - this automatically sets the correct epic type_id
- **IMPORTANT**: Use workitems_create with ALL properties at once - do NOT create then update!

**WORK-ITEM RELATIONS CAPABILITIES:**
**✅ CAN create relationships between work items using workitems_create_relation:**
- Relation types: blocking, blocked_by, duplicate, relates_to, start_before, start_after, finish_before, finish_after
- **CRITICAL**: You MUST collect actual work item IDs (UUIDs) FIRST before creating relations
- **WORKFLOW**: User says "Make issue A block issue B" → FIRST search for both issues to get their IDs → THEN create relation
- **NEVER** use work item names directly - always resolve to UUIDs first using search tools

**❌ CANNOT be set during workitems_create (requires separate API calls):**
- Adding to modules (use modules_add_work_items after creation)
- Adding to cycles (use cycles_add_work_items after creation)
- Adding to views (use issue_views_add_work_items after creation)

**EFFICIENCY RULE**: Always try to set as many properties as possible during creation to minimize API calls.


**IMPORTANT**: Analyze the user's request carefully to identify ALL required actions, not just the obvious ones.

{RETRIEVAL_TOOL_DESCRIPTIONS}

**Execution Guidelines:**
- Use search tools for entity resolution, NOT vector_search_tool
- Do NOT provide workspace_slug - auto-provided from context
- search_workitem_by_identifier requires format: PROJECT-123 as input argument

**WORKFLOW DECISION TREE:**

{WORK_TREE_INSTRUCTIONS}
"""  # noqa: E501

    if project_id:
        method_prompt += f"\n\n**🔥 PROJECT CONTEXT (CRITICAL):**\nProject ID: {project_id}\n\n**IMPORTANT SCOPING RULES:**\n- This is a PROJECT-LEVEL chat - ALL operations are scoped to THIS PROJECT ONLY\n- When the request mentions 'current cycle', 'current module', 'work items', etc. - it means ONLY within THIS PROJECT\n- Use this project_id for ALL tools that accept project_id parameter\n- DO NOT query across all projects - scope everything to THIS specific project\n- User refers to 'this project'/'the project'/'current project' = use this project_id"  # noqa: E501
    else:
        # Workspace-level context (no specific project)
        method_prompt += f"\n\n**🌐 WORKSPACE CONTEXT (CRITICAL):**\nWorkspace ID: {workspace_id}\n\n**IMPORTANT SCOPING RULES:**\n- This is a WORKSPACE-LEVEL chat - queries can span MULTIPLE PROJECTS\n- When the request mentions 'last cycle', 'this cycle', 'work items', etc. WITHOUT specifying a project - it could be in ANY project\n- Use list_member_projects (with a high limit) to get ALL projects in the workspace\n- Iterate through projects ONLY for entities that are inherently project-scoped (cycles/modules/states/labels). For workspace-wide work-item queries, use a SINGLE structured_db_tool call WITHOUT project_id (it will scope via workspace_id)\n- CRITICAL: Do NOT limit to 1 project unless the user specifically names or refers to a specific project"  # noqa: E501

    if enhanced_conversation_history and enhanced_conversation_history.strip():
        method_prompt += f"\n\n**CONVERSATION HISTORY & ACTION CONTEXT:**\n{enhanced_conversation_history}\n\nBased on this conversation history, you can reference previously mentioned entity IDs and use them as parameters in your tool calls. However, if the user asks for entity DATA/details, you still MUST call the appropriate retrieval tools - conversation history provides IDs for PARAMETERS, not complete entity data."  # noqa: E501
        method_prompt += HISTORY_FRESHNESS_WARNING
        address_user_by_name = False

    if user_id:
        method_prompt += f"\n\n**USER CONTEXT:**\nUser ID: {user_id}\nUse this when user refers to him/herself or 'I' or 'me' or 'my' or 'mine' or any other personal pronoun or any derivative of these words."  # noqa: E501

    if address_user_by_name:
        # Include user's first name if available from user_meta
        if user_meta and isinstance(user_meta, dict):
            first_name = user_meta.get("first_name") or user_meta.get("firstName")
            if first_name:
                method_prompt += f"\nUser's first name: {first_name}"
            last_name = user_meta.get("last_name") or user_meta.get("lastName")
            if last_name:
                method_prompt += f", and last name: {last_name}"
            email = user_meta.get("email")
            if email:
                method_prompt += f"\nUser's email: {email}"
            method_prompt += "\nUse the user's name (primarily first name) to address them in your responses.\n"
            method_prompt += "\nYou can reveal the user's name and email to them if requested. The name details here are primarily for greeting purposes. Use the user_id in tool calls if you need to get more user details.\n"  # noqa: E501
    else:
        method_prompt += "\nSkip greetings and get straight to the point."

    log.info(f"ENHANCED_CONVERSATION_HISTORY being sent to LLM:\n{enhanced_conversation_history}")

    # Inject clarification context if present (from previous turn's ask_for_clarification)
    if clarification_context and isinstance(clarification_context, dict):
        try:
            original_query_text = clarification_context.get("original_query")
            reason = clarification_context.get("reason")
            answer_text = clarification_context.get("answer_text")
            missing_fields = clarification_context.get("missing_fields") or []
            category_hints = clarification_context.get("category_hints") or []
            disambig = clarification_context.get("disambiguation_options") or []

            method_prompt += "\n\n**USER CLARIFICATION (previous turn):**\n"
            # CRITICAL: Include the original query to maintain full context
            if original_query_text:
                method_prompt += f"Original user request: {original_query_text}\n"
            if reason:
                method_prompt += f"Clarification reason: {reason}\n"
            if missing_fields:
                method_prompt += f"Missing fields resolved: {", ".join([str(x) for x in missing_fields])}\n"
            if category_hints:
                method_prompt += f"Category hints: {", ".join([str(x) for x in category_hints])}\n"
            if disambig:
                method_prompt += "The user was shown these options:\n"
                for idx, opt in enumerate(disambig, 1):
                    if isinstance(opt, dict):
                        opt_id = opt.get("id")
                        opt_name = opt.get("name") or opt.get("display_name") or ""
                        opt_identifier = opt.get("identifier") or ""
                        opt_email = opt.get("email") or ""

                        # Format based on what fields are available
                        if opt_email:
                            # User entity
                            method_prompt += f"  {idx}. {opt_name} ({opt_email}) → UUID: {opt_id}\n"
                        elif opt_identifier:
                            # Project/workitem entity
                            method_prompt += f"  {idx}. {opt_name} (Identifier: {opt_identifier}) → UUID: {opt_id}\n"
                        else:
                            # Generic entity
                            method_prompt += f"  {idx}. {opt_name} → UUID: {opt_id}\n"
            if answer_text:
                method_prompt += f"\nUser's clarification answer: {answer_text}\n"
            method_prompt += "\nIMPORTANT: The current user message is a clarification response to the original request above. Use the clarification answer to resolve missing information and continue with the ORIGINAL request, not as a new standalone request.\n"  # noqa E501
        except Exception:
            pass

    return method_prompt


# ------------------------------
# Clarification context builders
# ------------------------------


def build_clarification_context_block(clar_ctx: dict | None) -> str:
    """Builds a formatted clarification context block for prompts.

    Expected clar_ctx keys: original_query, reason, disambiguation_options (list of dicts), answer_text
    """
    try:
        if not clar_ctx or not isinstance(clar_ctx, dict):
            return ""

        original_query_text = clar_ctx.get("original_query")
        reason = clar_ctx.get("reason")
        disambig_options = clar_ctx.get("disambiguation_options") or []
        answer_text = clar_ctx.get("answer_text")

        parts: list[str] = []
        parts.append("\n\n**CLARIFICATION CONTEXT:**\n")
        if original_query_text:
            parts.append(f"Original user request: {original_query_text}\n")
        if reason:
            parts.append(f"Clarification reason: {reason}\n")
        if disambig_options:
            parts.append("The user was previously shown these options:\n")
            for idx, opt in enumerate(disambig_options, 1):
                if isinstance(opt, dict):
                    opt_id = opt.get("id")
                    opt_name = opt.get("name") or opt.get("display_name") or ""
                    opt_identifier = opt.get("identifier") or ""
                    opt_email = opt.get("email") or ""

                    if opt_email:
                        parts.append(f"  {idx}. {opt_name} ({opt_email}) → UUID: {opt_id}\n")
                    elif opt_identifier:
                        parts.append(f"  {idx}. {opt_name} (Identifier: {opt_identifier}) → UUID: {opt_id}\n")
                    else:
                        parts.append(f"  {idx}. {opt_name} → UUID: {opt_id}\n")
        if answer_text:
            parts.append(f"\nUser's clarification answer: {answer_text}\n")
        parts.append(
            "\nIMPORTANT: The current user message is a clarification response to the original request above. "
            "Use the clarification answer to resolve missing information and continue with the ORIGINAL request, "
            "not as a new standalone request.\n"
        )

        return "".join(parts)
    except Exception:
        return ""


def classify_tool(tool_name: str) -> Tuple[bool, bool]:
    """Return (is_retrieval_tool, is_action_tool) using registry first, then heuristics."""
    # 1) Registry check (authoritative if present)
    meta = get_tool_metadata(tool_name)
    if meta:
        kind = str(meta.get("kind") or "").lower()
        if kind == "retrieval":
            return True, False
        if kind == "action":
            return False, True
        # Fall through to heuristics if malformed

    # 2) Heuristics fallback
    # Include both prefix and substring patterns for robustness
    read_only_patterns = [
        "list_",  # prefix form like list_member_projects
        "get_",  # prefix form
        "retrieve_",  # prefix form
        "_list",
        "_retrieve",
        "_get",
        "_search",
        "search_",
    ]
    modifying_patterns = ["_create", "_update", "_delete", "_add", "_remove", "_archive", "_unarchive"]

    is_read_only = any(p in tool_name for p in read_only_patterns)
    has_modifying_pattern = any(p in tool_name for p in modifying_patterns)
    if has_modifying_pattern and is_read_only:
        is_read_only = False  # prioritize modifying for safety

    retrieval = is_retrieval_tool(tool_name) or is_read_only
    return retrieval, not retrieval


def format_tool_query_for_display(tool_name: str, tool_args: dict, user_query: Optional[str] = None) -> str:
    """Format tool arguments for display in streaming messages."""
    if not tool_args:
        return user_query or "the request"

    # For entity search tools, show the textual input used for search
    if tool_name.startswith("search_") and tool_name.endswith("_by_name"):
        entity_name = tool_args.get("name") or tool_args.get("display_name") or ""
        if entity_name:
            return f'"{str(entity_name)}"'

    # Special-case: user search using display_name
    if tool_name == "search_user_by_name":
        display_name = tool_args.get("display_name")
        if display_name:
            return f'"{str(display_name)}"'

    # For identifier-based searches, show the identifier
    if tool_name == "search_workitem_by_identifier":
        identifier = tool_args.get("identifier", "")
        if identifier:
            return f'"{identifier}"'

    if tool_name == "search_project_by_identifier":
        identifier = tool_args.get("identifier", "")
        if identifier:
            return f'"{identifier}"'
    if tool_name == "search_workitem_smart":
        q = tool_args.get("query", "")
        if q:
            return f'"{q}"'

    # For list tools, show what's being listed
    if tool_name.endswith("_list"):
        if "project_id" in tool_args:
            return "for project"
        elif "module_id" in tool_args:
            return "for module"
        elif "cycle_id" in tool_args:
            return "for cycle"
        else:
            return "all items"

    # For other tools, show the query parameter if available
    if "query" in tool_args:
        query = str(tool_args["query"])
        if query and query != "the request":
            return f'"{query}"'

    # Fallback to showing key parameters
    key_params = []
    for key, value in tool_args.items():
        if key in ["name", "display_name", "title", "description", "identifier", "search"] and value:
            key_params.append(f'{key}="{value}"')

    if key_params:
        return ", ".join(key_params)

    # Final fallback: use the actual user query
    return user_query or "the request"


def clean_tool_args_for_storage(tool_args: Dict[str, Any]) -> Dict[str, Union[str, List[str], Any]]:
    """
    Clean tool arguments before storing in database.
    Replace non-UUID values with specific placeholders that need to be resolved during execution.
    """
    cleaned_args: Dict[str, Union[str, List[str], Any]] = {}
    uuid_pattern = re.compile(r"^[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}$", re.IGNORECASE)

    # SPECIAL HANDLING: If tool_args contains a "project" dict with an "id" field that's a UUID,
    # extract it and set project_id directly to avoid later resolution
    project_id_extracted_from_dict = False
    if "project" in tool_args and isinstance(tool_args["project"], dict):
        project_block = tool_args["project"]
        project_id_candidate = project_block.get("id")
        if isinstance(project_id_candidate, str) and uuid_pattern.match(project_id_candidate):
            # Use the UUID from the project block directly
            cleaned_args["project_id"] = project_id_candidate
            project_id_extracted_from_dict = True

    for key, value in tool_args.items():
        if key.endswith("_id"):
            # Skip if we already extracted project_id from project block
            if key == "project_id" and project_id_extracted_from_dict:
                continue
            # For ID fields, only keep if they look like UUIDs
            if isinstance(value, str) and uuid_pattern.match(value):
                cleaned_args[key] = value
            else:
                # Store specific placeholder for non-UUID IDs
                entity_type = key.replace("_id", "")
                cleaned_args[key] = f"<id of {entity_type}: {value}>"
        elif key == "project":
            # Keep the project dict for action summary generation (display purposes)
            # We already extracted project_id above if it was a UUID
            cleaned_args[key] = value
        elif key == "issues" and isinstance(value, list):
            # For issues list, only convert non-UUID items to placeholders
            cleaned_issues = []
            for item in value:
                if isinstance(item, str) and uuid_pattern.match(item):
                    cleaned_issues.append(item)  # Keep UUIDs as-is
                else:
                    cleaned_issues.append(f"<id of workitem: {item}>")  # Convert names to placeholders
            cleaned_args[key] = cleaned_issues
        elif key == "workitems" and isinstance(value, list):
            # For workitems list, only convert non-UUID items to placeholders
            cleaned_workitems = []
            for item in value:
                if isinstance(item, str) and uuid_pattern.match(item):
                    cleaned_workitems.append(item)  # Keep UUIDs as-is
                else:
                    cleaned_workitems.append(f"<id of workitem: {item}>")  # Convert names to placeholders
            cleaned_args[key] = cleaned_workitems
        elif key == "workspace_slug":
            # Skip workspace_slug - it should be auto-filled from context during execution
            continue
        else:
            # For other fields, keep as is
            cleaned_args[key] = value

    return cleaned_args


def extract_entity_type_from_tool_name(tool_name: str) -> str:
    """Extract entity type from tool name (e.g., 'workitems_create' -> 'workitem')."""
    if tool_name.startswith("workitems_"):
        return "workitem"
    elif tool_name.startswith("epics_"):
        return "epic"  # Treat epics as their own entity type for user-facing display
    elif tool_name.startswith("projects_"):
        return "project"
    elif tool_name.startswith("cycles_"):
        return "cycle"
    elif tool_name.startswith("modules_"):
        return "module"
    elif tool_name.startswith("comments_"):
        return "comment"
    elif tool_name.startswith("pages_"):
        return "page"
    elif tool_name.startswith("labels_"):
        return "label"
    elif tool_name.startswith("states_"):
        return "state"
    elif tool_name.startswith("users_"):
        return "user"
    else:
        parts = tool_name.split("_")
        if len(parts) > 1:
            entity = parts[0]
            if entity.endswith("s") and entity not in ["issues", "users"]:
                entity = entity[:-1]
            return entity
        return "unknown"


def extract_action_type_from_tool_name(tool_name: str) -> str:
    """Extract action type from tool name (e.g., 'workitems_create' -> 'create')."""
    # Special case: relation operations are updates, not creates
    if "_create_relation" in tool_name:
        return "update"
    elif "_create" in tool_name:
        return "create"
    elif "_update" in tool_name:
        return "update"
    elif "_delete" in tool_name:
        return "delete"
    elif "_list" in tool_name:
        return "list"
    elif "_retrieve" in tool_name or "_get" in tool_name:
        return "retrieve"
    elif "_search" in tool_name:
        return "search"
    elif "_add" in tool_name:
        return "add"
    elif "_remove" in tool_name:
        return "remove"
    else:
        parts = tool_name.split("_")
        if len(parts) > 1:
            return parts[-1]
        return "unknown"


# ------------------------------
# Clarification formatting utils
# ------------------------------


def format_clarification_as_text(clarification_data: Dict[str, Any]) -> str:
    """Format structured clarification data as natural language text for frontend display.

    This helper lives here so any caller (endpoint or executor) can format
    clarification prompts consistently without duplicating logic.
    """
    try:
        reason = clarification_data.get("reason", "")
        questions = clarification_data.get("questions", []) or []
        disambiguation_options = clarification_data.get("disambiguation_options", []) or []
        clarification_data.get("missing_fields", []) or []

        text_parts: List[str] = []
        if reason:
            text_parts.append(f"❓ **{reason}**\n")

        for question in questions:
            text_parts.append(f"{str(question)}\n")

        if disambiguation_options:
            text_parts.append("\n**Please choose one:**\n")
            for i, option in enumerate(disambiguation_options, 1):
                if isinstance(option, dict):
                    display_name = option.get("display_name") or option.get("name") or option.get("title")
                    email = option.get("email")
                    identifier = option.get("identifier")
                    url = option.get("url")

                    if display_name and email:
                        # Likely a user - link only the name, show email separately
                        if url:
                            text_parts.append(f"{i}. [**{display_name}**]({url}) ({email})\n")
                        else:
                            text_parts.append(f"{i}. **{display_name}** ({email})\n")
                    elif display_name and "(" in display_name and ")" in display_name:
                        # Handle case where LLM combines name and email in single field like "John Doe (john@example.com)"
                        name_part = display_name.split("(")[0].strip()
                        if url:
                            text_parts.append(f"{i}. [**{name_part}**]({url}) ({display_name.split("(")[1]}\n")
                        else:
                            text_parts.append(f"{i}. **{display_name}**\n")
                    elif display_name and identifier:
                        # Likely a workitem
                        if url:
                            text_parts.append(f"{i}. [**{display_name}**]({url}) (ID: {identifier})\n")
                        else:
                            text_parts.append(f"{i}. **{display_name}** (ID: {identifier})\n")
                    elif display_name:
                        if url:
                            text_parts.append(f"{i}. [**{display_name}**]({url})\n")
                        else:
                            text_parts.append(f"{i}. **{display_name}**\n")
                    else:
                        text_parts.append(f"{i}. {str(option)}\n")
                else:
                    text_parts.append(f"{i}. {str(option)}\n")

        # if missing_fields:
        #     text_parts.append(f"\n*Missing information: {", ".join([str(m) for m in missing_fields])}*\n")

        text_parts.append("\n*Please provide your answer in your next message.*")

        return "".join(text_parts)
    except Exception:
        return "❓ I need clarification about your request. Please provide more details."


# ------------------------------
# Required fields preflight
# ------------------------------

# Central registry of required fields per action tool
REQUIRED_FIELDS_BY_TOOL: Dict[str, List[str]] = {
    # Workitems
    "workitems_create": ["project_id", "name"],
    # For updates, issue_id is sufficient at planning time; project_id is auto-resolved from issue_id during execution
    "workitems_update": ["issue_id"],
    # Modules
    "modules_create": ["name", "project_id"],
    "modules_add_work_items": ["module_id", "issues", "project_id"],
    "modules_remove_work_item": ["module_id", "issue_id", "project_id"],
    # Cycles
    "cycles_create": ["name", "project_id"],
    # Labels/States (project scoped)
    "labels_create": ["name", "project_id"],
    "states_create": ["name", "color", "project_id"],
    # Pages - project_id is conditionally required based on chat context
    # Will be handled specially in the clarification logic
    "pages_create_project_page": ["project_id", "name"],
    # Workspace pages don't require project_id
    "pages_create_workspace_page": ["name"],
    # Consolidated pages tool (workspace context): force scope selection via clarification
    "pages_create_page": ["project_id", "name"],
}


def resolve_from_context(required_key: str, tool_args: Dict[str, Any], action_context: Optional[Dict[str, Any]]) -> Optional[Any]:
    """Try to resolve a missing required field from the provided action_context.

    Currently supports mapping `project_id` from context.
    """
    try:
        if required_key == "project_id" and isinstance(action_context, dict):
            ctx_val = action_context.get("project_id")
            if ctx_val:
                return ctx_val
    except Exception:
        pass
    return None


def preflight_missing_required_fields(tool_name: str, tool_args: Dict[str, Any], action_context: Optional[Dict[str, Any]] = None) -> List[str]:
    """Return a list of required fields still missing after considering context.

    - Uses REQUIRED_FIELDS_BY_TOOL to determine required params
    - Treats values as present if in tool_args and truthy
    - Allows auto-resolving certain keys from action_context
    """
    missing: List[str] = []
    required = REQUIRED_FIELDS_BY_TOOL.get(tool_name, [])
    if not required:
        return missing

    args = tool_args or {}
    # Determine if this is an action tool; placeholders are allowed during planning for action tools
    try:
        _is_retrieval, _is_action = classify_tool(tool_name)
    except Exception:
        _is_action = False
    # UUID format for strict validation of *_id fields
    uuid_pattern = re.compile(r"^[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}$", re.IGNORECASE)
    for key in required:
        val = args.get(key)
        # Treat 'NEEDS_CLARIFICATION' as missing - it's a sentinel value from LLM
        # Also treat placeholders (e.g., "<id of project: X>") and non-UUID *_id values as missing
        is_missing = False

        if not val or val == "NEEDS_CLARIFICATION":
            is_missing = True
        elif key.endswith("_id"):
            # Special sentinel allowed for pages scope
            if isinstance(val, str) and key == "project_id" and val == "__workspace_scope__":
                is_missing = False
            elif isinstance(val, str):
                # Placeholders like "<id of project: X>" are allowed for ACTION tools during planning
                if "<id of" in val:
                    is_missing = not _is_action
                elif not uuid_pattern.match(val):
                    # Non-UUID strings (e.g., names) must be resolved; still missing
                    is_missing = True
            elif isinstance(val, dict):
                # If dict provided, require a valid UUID in 'id' key
                vid = val.get("id") if isinstance(val, dict) else None
                if not (isinstance(vid, str) and uuid_pattern.match(vid)):
                    is_missing = True
        # Non *_id fields: treat as present if truthy

        if not is_missing:
            continue
        # Try resolving from context
        ctx_val = resolve_from_context(key, args, action_context)
        if ctx_val:
            continue
        missing.append(key)

    return missing


async def handle_missing_required_fields(
    tool_name: str,
    tool_args: Dict[str, Any],
    action_context: Optional[Dict[str, Any]],
    missing_required: List[str],
    method_executor: Any,
    workspace_slug: str,
    chat_id: str,
    tool_id: str,
    current_step: int,
    combined_tool_query: str,
    is_project_chat: Optional[bool] = None,
) -> Optional[Dict[str, Any]]:
    """Handle missing required fields by creating clarification payload with disambiguation options.

    Returns a dict with:
        - clarification_payload: The clarification data to send to frontend
        - tool_message: ToolMessage to append to conversation
        - flow_step: Flow step dict to track the clarification
        - clarification_requested: Boolean flag indicating clarification was triggered

    Returns None if clarification creation fails.
    """
    import json

    from langchain_core.messages import ToolMessage

    from pi.app.models.enums import ExecutionStatus
    from pi.app.models.enums import FlowStepType
    from pi.services.chat.utils import standardize_flow_step_content

    try:
        # Seed category hints so downstream clarification can auto-populate options correctly
        category_hints: List[str] = []
        if tool_name.startswith("workitems_"):
            category_hints = ["workitems"]
        elif tool_name.startswith("pages_"):
            # CRITICAL: mark pages so clarification can fetch filtered project list
            category_hints = ["pages"]

        clarification_payload: Dict[str, Any] = {
            "reason": "Missing required field(s) for action",
            "questions": ["Which project should I use?" if "project_id" in missing_required else "Provide missing information"],
            "missing_fields": missing_required,
            "category_hints": category_hints,
        }

        # Build disambiguation options where possible for the primary missing field
        disambig_options: List[Dict[str, Any]] = []
        try:
            # Choose a primary field to clarify first
            # Special case: if module/cycle/etc need project context, prioritize project_id first
            priority = [
                "project_id",
                "module_id",
                "cycle_id",
                "label_id",
                "state_id",
                "assignee",
                "assignee_id",
                "user_id",
            ]

            # If both project_id and a project-scoped entity are missing, prioritize project_id
            project_scoped_entities = ["module_id", "cycle_id", "label_id", "state_id"]
            has_project_scoped = any(f in missing_required for f in project_scoped_entities)
            if "project_id" not in missing_required and has_project_scoped:
                # Project context exists, continue with normal priority
                primary = next((f for f in priority if f in missing_required), missing_required[0])
            elif "project_id" in missing_required and has_project_scoped:
                # Both project and project-scoped entity missing - ask for project first
                primary = "project_id"
            else:
                # Normal case
                primary = next((f for f in priority if f in missing_required), missing_required[0])

            if primary == "project_id":
                # Special handling for pages: add workspace-level option if not in project chat
                is_page_tool = tool_name in ("pages_create_project_page", "pages_create_workspace_page", "pages_create_page")

                # Debug logging
                from pi import logger

                log = logger.getChild(__name__)
                log.info(f"ChatID: {chat_id} - Clarification for tool={tool_name}, is_page_tool={is_page_tool}, is_project_chat={is_project_chat}")

                # If we're in workspace context (not project chat) and this is a page tool,
                # add "Workspace level" as the first option
                # Explicitly check for False or None (workspace context)
                if is_page_tool and is_project_chat is not True:
                    log.info(f"ChatID: {chat_id} - Adding workspace-level option for page creation")
                    disambig_options.append({
                        "id": "__workspace_scope__",
                        "name": "Workspace level",
                        "type": "scope",
                        "description": "Create page at workspace level (accessible across all projects)",
                    })

                # Prefer DB-backed, filtered project list to avoid archived/deleted noise
                try:
                    ws_id = (action_context or {}).get("workspace_id") if isinstance(action_context, dict) else None
                    if ws_id:
                        from pi.core.db.plane import PlaneDBPool as _DB

                        query = """
                            SELECT p.id, p.name, p.identifier
                            FROM projects p
                            WHERE p.workspace_id = $1
                              AND p.deleted_at IS NULL
                              AND p.archived_at IS NULL
                            ORDER BY p.name
                            LIMIT 50
                            """
                        rows = await _DB.fetch(query, (ws_id,))
                        for r in rows or []:
                            option = {"id": str(r["id"]), "name": r["name"], "type": "project"}
                            if r.get("identifier"):
                                option["identifier"] = r["identifier"]
                            disambig_options.append(option)
                    else:
                        # Fallback to API list with defensive filtering
                        proj_res = await method_executor.execute(
                            "projects",
                            "list",
                            workspace_slug=workspace_slug,
                            per_page=50,
                        )
                        if isinstance(proj_res, dict) and proj_res.get("success"):
                            data_block = proj_res.get("data")
                            candidates = []
                            if isinstance(data_block, list):
                                candidates = data_block
                            elif isinstance(data_block, dict):
                                for key in ("results", "items", "projects", "data"):
                                    val = data_block.get(key)
                                    if isinstance(val, list):
                                        candidates = val
                                        break
                            for it in candidates:
                                try:
                                    pid = it.get("id") if isinstance(it, dict) else None
                                    name = it.get("name") if isinstance(it, dict) else None
                                    identifier = it.get("identifier") if isinstance(it, dict) else None
                                    is_archived = it.get("archived_at") is not None
                                    is_deleted = it.get("deleted_at") is not None

                                    if pid and name and not is_archived and not is_deleted:
                                        option = {"id": str(pid), "name": str(name), "type": "project"}
                                        if identifier:
                                            option["identifier"] = str(identifier)
                                        disambig_options.append(option)
                                except Exception:
                                    continue
                except Exception:
                    # As a last resort, leave options empty
                    pass

                # Adjust question for pages vs other entities
                if is_page_tool and is_project_chat is not True:
                    clarification_payload["questions"] = ["Where would you like to create this page?"]
                else:
                    clarification_payload["questions"] = ["Which project should I use?"]

            elif primary == "module_id":
                # Need project context to scope modules
                proj = tool_args.get("project_id") or (action_context.get("project_id") if action_context else None)
                if proj:
                    mod_res = await method_executor.execute("modules", "list", project_id=proj, workspace_slug=workspace_slug)
                    if isinstance(mod_res, dict) and mod_res.get("success"):
                        data_block = mod_res.get("data")
                        candidates = []
                        if isinstance(data_block, list):
                            candidates = data_block
                        elif isinstance(data_block, dict):
                            for key in ("results", "items", "modules", "data"):
                                val = data_block.get(key)
                                if isinstance(val, list):
                                    candidates = val
                                    break
                        for it in candidates:
                            try:
                                mid = it.get("id") if isinstance(it, dict) else None
                                name = it.get("name") if isinstance(it, dict) else None
                                if mid and name:
                                    disambig_options.append({"id": str(mid), "name": str(name)})
                            except Exception:
                                continue
                clarification_payload["questions"] = ["Which module should I use?"]

            elif primary == "cycle_id":
                proj = tool_args.get("project_id") or (action_context.get("project_id") if action_context else None)
                if proj:
                    cyc_res = await method_executor.execute("cycles", "list", project_id=proj, workspace_slug=workspace_slug, per_page=50)
                    if isinstance(cyc_res, dict) and cyc_res.get("success"):
                        data_block = cyc_res.get("data")
                        candidates = []
                        if isinstance(data_block, list):
                            candidates = data_block
                        elif isinstance(data_block, dict):
                            for key in ("results", "items", "cycles", "data"):
                                val = data_block.get(key)
                                if isinstance(val, list):
                                    candidates = val
                                    break
                        for it in candidates:
                            try:
                                cid = it.get("id") if isinstance(it, dict) else None
                                name = it.get("name") if isinstance(it, dict) else None
                                if cid and name:
                                    disambig_options.append({"id": str(cid), "name": str(name), "type": "cycle", "project_id": str(proj)})
                            except Exception:
                                continue
                clarification_payload["questions"] = ["Which cycle should I use?"]

            elif primary == "label_id":
                proj = tool_args.get("project_id") or (action_context.get("project_id") if action_context else None)
                if proj:
                    lab_res = await method_executor.execute("labels", "list", project_id=proj, workspace_slug=workspace_slug)
                    if isinstance(lab_res, dict) and lab_res.get("success"):
                        data_block = lab_res.get("data")
                        candidates = []
                        if isinstance(data_block, list):
                            candidates = data_block
                        elif isinstance(data_block, dict):
                            for key in ("results", "items", "labels", "data"):
                                val = data_block.get(key)
                                if isinstance(val, list):
                                    candidates = val
                                    break
                        for it in candidates:
                            try:
                                lid = it.get("id") if isinstance(it, dict) else None
                                name = it.get("name") if isinstance(it, dict) else None
                                color = it.get("color") if isinstance(it, dict) else None
                                if lid and name:
                                    opt = {"id": str(lid), "name": str(name)}
                                    if color:
                                        opt["color"] = str(color)
                                    disambig_options.append(opt)
                            except Exception:
                                continue
                clarification_payload["questions"] = ["Which label should I use?"]

            elif primary == "state_id":
                proj = tool_args.get("project_id") or (action_context.get("project_id") if action_context else None)
                if proj:
                    st_res = await method_executor.execute("states", "list", project_id=proj, workspace_slug=workspace_slug)
                    if isinstance(st_res, dict) and st_res.get("success"):
                        data_block = st_res.get("data")
                        candidates = []
                        if isinstance(data_block, list):
                            candidates = data_block
                        elif isinstance(data_block, dict):
                            for key in ("results", "items", "states", "data"):
                                val = data_block.get(key)
                                if isinstance(val, list):
                                    candidates = val
                                    break
                        for it in candidates:
                            try:
                                sid = it.get("id") if isinstance(it, dict) else None
                                name = it.get("name") if isinstance(it, dict) else None
                                group = it.get("group") if isinstance(it, dict) else None
                                if sid and name:
                                    opt = {"id": str(sid), "name": str(name)}
                                    if group:
                                        opt["group"] = str(group)
                                    disambig_options.append(opt)
                            except Exception:
                                continue
                clarification_payload["questions"] = ["Which state should I use?"]

            elif primary in ("assignee", "assignee_id", "user_id"):
                # Prefer project members if project context present
                proj = tool_args.get("project_id") or (action_context.get("project_id") if action_context else None)
                if proj:
                    mem_res = await method_executor.execute("members", "get_project_members", project_id=proj, workspace_slug=workspace_slug)
                else:
                    mem_res = await method_executor.execute("members", "get_workspace_members", workspace_slug=workspace_slug)
                if isinstance(mem_res, dict) and mem_res.get("success"):
                    data_block = mem_res.get("data")
                    candidates = []
                    if isinstance(data_block, list):
                        candidates = data_block
                    elif isinstance(data_block, dict):
                        for key in ("results", "items", "members", "data"):
                            val = data_block.get(key)
                            if isinstance(val, list):
                                candidates = val
                                break
                    for it in candidates:
                        try:
                            uid = (it.get("id") if isinstance(it, dict) else None) or it.get("member_id") if isinstance(it, dict) else None
                            display_name = (
                                (it.get("display_name") if isinstance(it, dict) else None) or it.get("name") if isinstance(it, dict) else None
                            )
                            email = it.get("email") if isinstance(it, dict) else None
                            if uid and (display_name or email):
                                opt = {"id": str(uid)}
                                if display_name:
                                    opt["display_name"] = str(display_name)
                                if email:
                                    opt["email"] = str(email)
                                disambig_options.append(opt)
                        except Exception:
                            continue
                clarification_payload["questions"] = ["Which user should I use?"]
        except Exception:
            # Best-effort only; lack of options shouldn't block clarification
            pass

        # Enrich options with entity URLs (projects/users/cycles/modules) for better UX in clarification
        try:
            if disambig_options:
                from pi.config import settings as _settings

                base_url = _settings.plane_api.FRONTEND_URL
                if base_url and isinstance(workspace_slug, str) and workspace_slug:
                    enriched: List[Dict[str, Any]] = []
                    for _opt in disambig_options:
                        if isinstance(_opt, dict):
                            _opt2 = dict(_opt)
                            _typ = _opt2.get("type")
                            _idv = _opt2.get("id")
                            _proj_id = _opt2.get("project_id")
                            try:
                                if _typ == "project" and _idv:
                                    _opt2["url"] = f"{base_url}/{workspace_slug}/projects/{_idv}/overview/"
                                elif _typ == "cycle" and _idv and _proj_id:
                                    _opt2["url"] = f"{base_url}/{workspace_slug}/projects/{_proj_id}/cycles/{_idv}/"
                                elif _typ == "module" and _idv and _proj_id:
                                    _opt2["url"] = f"{base_url}/{workspace_slug}/projects/{_proj_id}/modules/{_idv}/"
                                elif _typ == "user" and _idv:
                                    _opt2["url"] = f"{base_url}/{workspace_slug}/profile/{_idv}/"
                            except Exception:
                                pass
                            enriched.append(_opt2)
                    disambig_options = enriched
        except Exception:
            pass

        if disambig_options:
            clarification_payload["disambiguation_options"] = disambig_options

        # Create a tool message responding to the tool_call to satisfy LLM protocol
        tool_message = None
        with contextlib.suppress(Exception):
            tool_message = ToolMessage(content=json.dumps(clarification_payload), tool_call_id=tool_id)

        # Log clarification payload synthesized during preflight
        with contextlib.suppress(Exception):
            log.info(
                f"{"*" * 100}\nChatID: {chat_id} - ASK_FOR_CLARIFICATION payload (preflight): {json.dumps(clarification_payload, default=str)}\n{"*" * 100}"  # noqa: E501
            )

        # Track flow step for clarification
        flow_step = {
            "step_order": current_step,
            "step_type": FlowStepType.TOOL,
            "tool_name": "ask_for_clarification",
            "content": standardize_flow_step_content(clarification_payload, FlowStepType.TOOL),
            "execution_data": {
                "args": tool_args,
                "clarification_pending": True,
                "clarification_payload": clarification_payload,
                # CRITICAL: Store the original query so we can reconstruct full context on clarification follow-up
                "original_query": combined_tool_query,
            },
            "is_planned": False,
            "is_executed": False,
            "execution_success": ExecutionStatus.PENDING,
        }

        return {
            "clarification_payload": clarification_payload,
            "tool_message": tool_message,
            "flow_step": flow_step,
            "clarification_requested": True,
        }

    except Exception:
        return None


async def stream_content_in_chunks(content: str, words_per_chunk: int = 15, delay_seconds: float = 0.08) -> AsyncIterator[str]:
    """
    Stream content in chunks of words with a slight delay to simulate streaming.

    Args:
        content: The full content to stream
        words_per_chunk: Number of words to include in each chunk (default: 15)
        delay_seconds: Delay between chunks in seconds (default: 0.08)

    Yields:
        Content chunks as strings
    """
    if not content:
        return

    # Split by whitespace but keep delimiters to preserve formatting (newlines, tabs, etc.)
    # This ensures tables and other formatted text are preserved exactly.
    tokens = re.split(r"(\s+)", content)

    current_chunk = []
    word_count = 0

    for token in tokens:
        current_chunk.append(token)
        # Count non-whitespace tokens as words
        if token and not token.isspace():
            word_count += 1

        if word_count >= words_per_chunk:
            yield "".join(current_chunk)
            current_chunk = []
            word_count = 0
            await asyncio.sleep(delay_seconds)

    # Yield remaining content
    if current_chunk:
        yield "".join(current_chunk)


async def batch_llm_stream_by_words(llm_stream: AsyncIterator[Any], words_per_batch: int = 10) -> AsyncIterator[str]:
    """
    Batch LLM stream chunks in real-time by word count to reduce browser event overhead.

    This function collects chunks from an LLM stream as they arrive and batches them
    by word count before yielding. Unlike stream_content_in_chunks which operates on
    complete content with artificial delays, this performs true real-time batching
    without delays.

    Args:
        llm_stream: Async iterator of LLM chunks (e.g., from llm.astream())
        words_per_batch: Number of words to accumulate before yielding a batch (default: 10)

    Yields:
        Batched content chunks as strings
    """
    current_batch = []
    word_count = 0

    async for chunk in llm_stream:
        # Extract content from LLM chunk (handles different LLM response formats)
        chunk_content = getattr(chunk, "content", None)
        if not chunk_content:
            continue

        chunk_str = str(chunk_content)

        # Split the chunk into tokens (words and whitespace)
        # Using the same pattern as stream_content_in_chunks to preserve formatting
        tokens = re.split(r"(\s+)", chunk_str)

        for token in tokens:
            current_batch.append(token)
            # Count non-whitespace tokens as words
            if token and not token.isspace():
                word_count += 1

            # Yield batch when word count threshold is reached
            if word_count >= words_per_batch:
                yield "".join(current_batch)
                current_batch = []
                word_count = 0

    # Yield any remaining content
    if current_batch:
        yield "".join(current_batch)
